{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lLGJyJthW1F-",
    "outputId": "bfd159ba-fcac-4668-8fd6-ba50f5b13f5e"
   },
   "outputs": [],
   "source": [
    "!pip install tokenizers==0.9.4\n",
    "!pip install simpletransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G9oN1CmeAJIq"
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, AdamW, DistilBertModel, DistilBertConfig\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import time\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LbVh7zgKnJRL",
    "outputId": "ec8cbe8a-e294-4847-cf40-fb09a1dacea3"
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCSs4ei1Xor8"
   },
   "source": [
    "## Read data from csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tLEIXzsi07C8"
   },
   "outputs": [],
   "source": [
    "def read_train_and_test(train_path, test_path): \n",
    "    train = pd.read_csv(train_path)\n",
    "    test = pd.read_csv(test_path)\n",
    "    return train, test\n",
    "\n",
    "train_path = \"../input/raw-train-test/train.csv\"\n",
    "test_path = \"../input/raw-train-test/test.csv\"\n",
    "train_csv, test_csv = read_train_and_test(train_path, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y_4ZHk66VAA6",
    "outputId": "e2289aac-c523-4107-bf83-f9a831bf55b7"
   },
   "outputs": [],
   "source": [
    "train_labels = list(train_csv.label.values)\n",
    "print(train_labels.count(0))\n",
    "print(train_labels.count(1))\n",
    "print(train_labels.count(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "36MMpQTxMCaA",
    "outputId": "45ad5a92-9cf7-42b3-86dc-d53786eec0b1"
   },
   "outputs": [],
   "source": [
    "print(train_csv.tweet.values[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cyRsPqwLX1wy"
   },
   "source": [
    "## Run tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DvIQKI-AtzJY",
    "outputId": "94d4bd81-f261-428c-a9c4-e9b80455effd"
   },
   "outputs": [],
   "source": [
    "def run_tokenizer(train_csv, test_csv, merge_label=False, add_token=False):\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased') \n",
    "    if add_token:\n",
    "      tokenizer.add_tokens(add_token)\n",
    "\n",
    "    def get_max_len(tokenizer, train_csv):\n",
    "        tweets = train_csv.tweet.values\n",
    "        max_length = 0\n",
    "        for t in tweets:\n",
    "          ids = tokenizer.encode(t)\n",
    "          max_length = max(len(ids),max_length)\n",
    "        return max_length\n",
    "\n",
    "    max_length = get_max_len(tokenizer, train_csv)\n",
    "    train_tweets, train_labels = train_csv.tweet.values, train_csv.label.values\n",
    "    test_tweets, test_labels = test_csv.tweet.values, test_csv.label.values\n",
    "    if merge_label == True:\n",
    "       train_labels = [l if l ==0 else 1 for l in train_labels]\n",
    "       test_labels = [l if l ==0 else 1 for l in test_labels]\n",
    "\n",
    "    def tokenize_for_tweet(tokenizer, tweets, labels):\n",
    "        input_ids = []\n",
    "        attention_masks = []\n",
    "\n",
    "        for t in tweets:\n",
    "            input_dict = tokenizer.encode_plus(t, add_special_tokens=True, max_length=max_length, truncation=True, padding='max_length',return_tensors='pt')\n",
    "            input_ids.append(input_dict['input_ids'])\n",
    "            attention_masks.append(input_dict['attention_mask'])\n",
    "        input_ids = torch.cat(input_ids,dim=0)\n",
    "        attention_masks = torch.cat(attention_masks,dim=0)\n",
    "        labels=torch.tensor(labels)\n",
    "        dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "        return dataset\n",
    "        \n",
    "    train_dataset = tokenize_for_tweet(tokenizer, train_tweets, train_labels)\n",
    "    test_dataset = tokenize_for_tweet(tokenizer, test_tweets, test_labels)\n",
    "    num_label = 3 if merge_label == False else 2\n",
    "    return train_dataset, test_dataset, num_label, tokenizer\n",
    "\n",
    "#tokens = ['<SWEAR-0>', '<SWEAR-1>', '<SWEAR-2>']\n",
    "train_dataset, test_dataset, num_label, tokenizer = run_tokenizer(train_csv, test_csv, merge_label = False)#,add_token = tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nE6x0jARX7hy"
   },
   "source": [
    "## Make data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mAfIYownmjsZ"
   },
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, sampler = RandomSampler(train_dataset), batch_size = batch_size)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, sampler = SequentialSampler(test_dataset), batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zcNUTLkIYAnd"
   },
   "source": [
    "## Difine classifier and adversary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b18YlcZR81n5"
   },
   "outputs": [],
   "source": [
    "configuration = DistilBertConfig()\n",
    "#configuration.output_hidden_states = True\n",
    "#print(configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Foric77dco5V"
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "  def __init__(self, num_label):\n",
    "    super().__init__()\n",
    "    self.bert = DistilBertModel.from_pretrained('distilbert-base-cased')\n",
    "    #self.bert.resize_token_embeddings(len(tokenizer))\n",
    "    self.linear = nn.Linear(configuration.hidden_size, num_label)\n",
    "\n",
    "  def forward(self, input_ids, attention_mask): # input_id [batch_size, sentence_length]\n",
    "    last_hidden_state = self.bert(input_ids, attention_mask)[0] # last_hidden_state [batch_size, sentence_length, hidden_size]\n",
    "    last_hidden_state = torch.mean(last_hidden_state, dim=1) # last_hidden_state [batch_size, hidden_size]\n",
    "    output = self.linear(last_hidden_state) # output [batch_size, num_label]\n",
    "    return last_hidden_state, output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RRSb2kh4_9YB"
   },
   "outputs": [],
   "source": [
    "class Adversary(nn.Module):\n",
    "  def __init__(self, num_protected_label, hidden_size):\n",
    "    super().__init__()\n",
    "    self.linear1 = nn.Linear(configuration.hidden_size, hidden_size)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.linear2 = nn.Linear(hidden_size, num_protected_label)\n",
    "\n",
    "  def forward(self, clf_last_state):\n",
    "    output1 = self.relu(self.linear1(clf_last_state))\n",
    "    output = self.linear2(output1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKmFT1zKYQJ5"
   },
   "source": [
    "## Training and evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "laM3Y-4qFMRN"
   },
   "outputs": [],
   "source": [
    "def joint_training(clf, adv, epochs, clf_optimizer, adv_optimizer, train_dataloader, test_dataloader, alpha, model_name):\n",
    "    best_acc = 0\n",
    "    for e in range(epochs):\n",
    "        print('training {} epoch...'.format(e+1))\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss, total_clf_loss, total_adv_loss = 0, 0, 0\n",
    "\n",
    "        clf.train(True)\n",
    "        adv.train(True)\n",
    "        for input, mask, label in train_dataloader:\n",
    "            input = input.to(DEVICE)\n",
    "            mask = mask.to(DEVICE)\n",
    "            label=label.to(DEVICE)\n",
    "\n",
    "            protected_label = torch.tensor([1 if l == 1 else 0 for l in label], dtype=torch.long).to(DEVICE) # 0 no-offensive 1 offensive\n",
    "            \n",
    "            clf.zero_grad()\n",
    "            adv.zero_grad()\n",
    "\n",
    "            last_hidden_state, clf_output = clf(input_ids=input, attention_mask=mask)\n",
    "\n",
    "            adv_output = adv(last_hidden_state)\n",
    "\n",
    "            clf_loss = loss_function(clf_output, label)\n",
    "            adv_loss = loss_function(adv_output, protected_label)\n",
    "\n",
    "            total_loss = clf_loss - alpha*adv_loss\n",
    "\n",
    "            train_loss += total_loss.item()\n",
    "            total_clf_loss += clf_loss.item()\n",
    "            total_adv_loss += adv_loss.item()\n",
    "\n",
    "            total_loss.backward(retain_graph=True)\n",
    "            clf_optimizer.step()\n",
    "\n",
    "            adv_loss.backward()\n",
    "            adv_optimizer.step()\n",
    "            \n",
    "\n",
    "        avg_train_loss = train_loss / len(train_dataloader)\n",
    "        sec = time.time()-start_time\n",
    "        print('{} seconds used......'.format(sec))\n",
    "        print(\"{} training finished! average train loss: {}\".format(e+1,avg_train_loss))\n",
    "        print('total clf loss: {} total adv loss: {}'.format(total_clf_loss, total_adv_loss))\n",
    "        print('evaluating...')\n",
    "        best_acc = evaluate(clf, best_acc, test_dataloader, model_name, str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5FAxcsnLHYWp"
   },
   "outputs": [],
   "source": [
    "def evaluate(clf, best_acc, test_dataloader, model_name, epoch):\n",
    "    num_total, num_correct = 0, 0\n",
    "    clf.train(False)\n",
    "    with torch.no_grad():\n",
    "      eval_loss = 0\n",
    "      true_labels, predict_labels = [], []\n",
    "      for input, mask, label in test_dataloader:\n",
    "          clf.zero_grad()\n",
    "          \n",
    "          input = input.to(DEVICE)\n",
    "          mask = mask.to(DEVICE)\n",
    "          label = label.to(DEVICE)\n",
    "\n",
    "          last_hidden_state, output = clf(input_ids=input, attention_mask=mask)\n",
    "\n",
    "          loss = loss_function(output, label)\n",
    "\n",
    "          predict_label = torch.argmax(output, dim=1)\n",
    "\n",
    "          true_labels += label.tolist()\n",
    "          predict_labels += predict_label.tolist()\n",
    "\n",
    "          num_correct += (predict_label == label).sum().item()\n",
    "          num_total += len(label)\n",
    "\n",
    "          eval_loss += loss.item()\n",
    "\n",
    "      avg_eval_loss = eval_loss / len(test_dataloader)\n",
    "\n",
    "      acc = num_correct/num_total\n",
    "      if acc > best_acc:\n",
    "        best_acc = acc\n",
    "      torch.save(clf, epoch+model_name)\n",
    "      print_matrix(true_labels, predict_labels)\n",
    "\n",
    "    print('average eval_loss: {}, accuracy: {}'.format(avg_eval_loss,acc))\n",
    "    return best_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hV2RTigKYfSu"
   },
   "source": [
    "## Define the classifier and adversary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hIWH9p-8_Gz4",
    "outputId": "80f69313-67a9-4dc0-a442-8534312fc81d"
   },
   "outputs": [],
   "source": [
    "classifier = Classifier(num_label).to(DEVICE)\n",
    "\n",
    "adversary = Adversary(2, 120).to(DEVICE)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "clf_optimizer = AdamW(classifier.parameters(),lr = 2e-5, eps = 1e-8)\n",
    "\n",
    "adv_optimizer = torch.optim.AdamW(adversary.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bDBVcb9HYIRg"
   },
   "source": [
    "## Import some tools for evaluation after each training epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WpoTduN5MCaE"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kkQQj3zDMCaE"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes, normalize=False, title=None, cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    #classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aFFmYy2aMCaE"
   },
   "outputs": [],
   "source": [
    "def print_matrix(true_labels, predict_labels, default_classes=['hate','offensive','neither']):\n",
    "  cm = confusion_matrix(true_labels, predict_labels)\n",
    "  plot_confusion_matrix(true_labels, predict_labels, classes=default_classes ,title='Confusion matrix without rebalance')\n",
    "\n",
    "  #Plot normalized confusion matrix\n",
    "  plot_confusion_matrix(true_labels, predict_labels, classes=default_classes, normalize=True,title='Normalized confusion matrix without rebalance')\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "  print(classification_report(true_labels, predict_labels, target_names=default_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUsp9GmZZQZ2"
   },
   "source": [
    "## Joint training\n",
    "In this step, the total loss which is defined as L = L<sub>clf</sub> − α∗L<sub>adv</sub> is used for backpropagation as well as adversary loss. Hence, α is also a import hyperparameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SoXzLzmgKP8Z",
    "outputId": "7416bfd9-639a-469c-b3e3-f450c84dc111"
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "alpha = 0.05\n",
    "model_name = 'adv_model_hate_as_offensive'\n",
    "joint_training(classifier, adversary, epochs, clf_optimizer, adv_optimizer, train_dataloader, test_dataloader, alpha, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ef7rhBsgaWbw"
   },
   "source": [
    "## Rebalance the number of instances in classes\n",
    "In the prevous experiment, rebalancing is an effective method to increase recall rate for hate speech class. (However, the scores of other classes will decrease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sCWBAqc4MCaF"
   },
   "outputs": [],
   "source": [
    "def rebalance_dataset(dataset):\n",
    "    data_0 = [inst for inst in dataset if inst[2]==0]\n",
    "    data_1 = [inst for inst in dataset if inst[2]==1]\n",
    "    data_2 = [inst for inst in dataset if inst[2]==2]\n",
    "    random.shuffle(data_0)\n",
    "    random.shuffle(data_1)\n",
    "    random.shuffle(data_2)\n",
    "    num_data0 = len(data_0)\n",
    "    balanced_dataset = data_0+data_1[:num_data0]+data_2[:num_data0]\n",
    "    return balanced_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sa8xJ7wRMCaF"
   },
   "outputs": [],
   "source": [
    "re_train_dataset = rebalance_dataset(train_dataset)\n",
    "re_test_dataset = rebalance_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lLoCX_30dm9m"
   },
   "outputs": [],
   "source": [
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I66AVk9iMCaF"
   },
   "outputs": [],
   "source": [
    "re_train_dataloader = DataLoader(re_train_dataset, sampler = RandomSampler(re_train_dataset), batch_size = batch_size)\n",
    "re_test_dataloader = DataLoader(re_test_dataset, sampler = RandomSampler(re_test_dataset), batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HzXhQc6HMCaF"
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "alpha = 0.05\n",
    "model_name = 'adv_model_hate_as_offensive'\n",
    "joint_training(classifier, adversary, epochs, clf_optimizer, adv_optimizer, re_train_dataloader, test_dataloader, alpha, model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
